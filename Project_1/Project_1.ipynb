{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec826f1-50a0-43c5-ace6-b0c186350fe5",
   "metadata": {},
   "source": [
    "# Import librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5010c1a9-3c75-45d6-9f22-cad368c5876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca3d32-a88f-4bac-a08e-d7d55eeffc7b",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b454d15e-9f4e-47d0-adbe-d9ec0f5e95bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Description</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Market capitalization as on March 28, 2024\\n(In lakhs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>3034.05</td>\n",
       "      <td>3050.00</td>\n",
       "      <td>3020.00</td>\n",
       "      <td>3026.30</td>\n",
       "      <td>3026.30</td>\n",
       "      <td>4110291.0</td>\n",
       "      <td>Reliance Industries Limited engages in hydroca...</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>2.010560e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>3023.90</td>\n",
       "      <td>3055.00</td>\n",
       "      <td>3023.55</td>\n",
       "      <td>3040.20</td>\n",
       "      <td>3040.20</td>\n",
       "      <td>3769275.0</td>\n",
       "      <td>Reliance Industries Limited engages in hydroca...</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>2.010560e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>2984.80</td>\n",
       "      <td>3024.85</td>\n",
       "      <td>2980.70</td>\n",
       "      <td>3018.05</td>\n",
       "      <td>3018.05</td>\n",
       "      <td>4929970.0</td>\n",
       "      <td>Reliance Industries Limited engages in hydroca...</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>2.010560e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>2962.00</td>\n",
       "      <td>3000.95</td>\n",
       "      <td>2954.15</td>\n",
       "      <td>2984.80</td>\n",
       "      <td>2984.80</td>\n",
       "      <td>6259938.0</td>\n",
       "      <td>Reliance Industries Limited engages in hydroca...</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>2.010560e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>2970.00</td>\n",
       "      <td>3019.00</td>\n",
       "      <td>2952.80</td>\n",
       "      <td>2991.40</td>\n",
       "      <td>2991.40</td>\n",
       "      <td>5956681.0</td>\n",
       "      <td>Reliance Industries Limited engages in hydroca...</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>2.010560e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     Open     High      Low    Close  Adj Close     Volume  \\\n",
       "0 2024-07-30  3034.05  3050.00  3020.00  3026.30    3026.30  4110291.0   \n",
       "1 2024-07-29  3023.90  3055.00  3023.55  3040.20    3040.20  3769275.0   \n",
       "2 2024-07-26  2984.80  3024.85  2980.70  3018.05    3018.05  4929970.0   \n",
       "3 2024-07-25  2962.00  3000.95  2954.15  2984.80    2984.80  6259938.0   \n",
       "4 2024-07-24  2970.00  3019.00  2952.80  2991.40    2991.40  5956681.0   \n",
       "\n",
       "                                         Description    Symbol  \\\n",
       "0  Reliance Industries Limited engages in hydroca...  RELIANCE   \n",
       "1  Reliance Industries Limited engages in hydroca...  RELIANCE   \n",
       "2  Reliance Industries Limited engages in hydroca...  RELIANCE   \n",
       "3  Reliance Industries Limited engages in hydroca...  RELIANCE   \n",
       "4  Reliance Industries Limited engages in hydroca...  RELIANCE   \n",
       "\n",
       "                  Company Name  \\\n",
       "0  Reliance Industries Limited   \n",
       "1  Reliance Industries Limited   \n",
       "2  Reliance Industries Limited   \n",
       "3  Reliance Industries Limited   \n",
       "4  Reliance Industries Limited   \n",
       "\n",
       "   Market capitalization as on March 28, 2024\\n(In lakhs)  \n",
       "0                                       2.010560e+08       \n",
       "1                                       2.010560e+08       \n",
       "2                                       2.010560e+08       \n",
       "3                                       2.010560e+08       \n",
       "4                                       2.010560e+08       "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df = pd.read_csv('data/adjusted_stock_data.csv')\n",
    "stock_df['Date'] = pd.to_datetime(stock_df['Date'])\n",
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e2df54-83f0-4098-8536-4bd8e18bf366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Company Name_x</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Company Name_y</th>\n",
       "      <th>Description</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Market capitalization as on March 28, 2024\\n(In lakhs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>9.00Dividend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>Reliance Industries Limited engages in hydroca...</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>2.010560e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-18</td>\n",
       "      <td>8.00Dividend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>Reliance Industries Limited engages in hydroca...</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>2.010560e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>7.00Dividend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>Reliance Industries Limited engages in hydroca...</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>2.010560e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>6.50Dividend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>Reliance Industries Limited engages in hydroca...</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>2.010560e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>6.44Dividend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>Reliance Industries Limited engages in hydroca...</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries Limited</td>\n",
       "      <td>2.010560e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date          Open  High  Low  Close  Adj Close  Volume  \\\n",
       "0 2023-08-21  9.00Dividend   NaN  NaN    NaN        NaN     NaN   \n",
       "1 2022-08-18  8.00Dividend   NaN  NaN    NaN        NaN     NaN   \n",
       "2 2021-06-11  7.00Dividend   NaN  NaN    NaN        NaN     NaN   \n",
       "3 2020-07-02  6.50Dividend   NaN  NaN    NaN        NaN     NaN   \n",
       "4 2019-08-02  6.44Dividend   NaN  NaN    NaN        NaN     NaN   \n",
       "\n",
       "                Company Name_x    Ticker               Company Name_y  \\\n",
       "0  Reliance Industries Limited  RELIANCE  Reliance Industries Limited   \n",
       "1  Reliance Industries Limited  RELIANCE  Reliance Industries Limited   \n",
       "2  Reliance Industries Limited  RELIANCE  Reliance Industries Limited   \n",
       "3  Reliance Industries Limited  RELIANCE  Reliance Industries Limited   \n",
       "4  Reliance Industries Limited  RELIANCE  Reliance Industries Limited   \n",
       "\n",
       "                                         Description    Symbol  \\\n",
       "0  Reliance Industries Limited engages in hydroca...  RELIANCE   \n",
       "1  Reliance Industries Limited engages in hydroca...  RELIANCE   \n",
       "2  Reliance Industries Limited engages in hydroca...  RELIANCE   \n",
       "3  Reliance Industries Limited engages in hydroca...  RELIANCE   \n",
       "4  Reliance Industries Limited engages in hydroca...  RELIANCE   \n",
       "\n",
       "                  Company Name  \\\n",
       "0  Reliance Industries Limited   \n",
       "1  Reliance Industries Limited   \n",
       "2  Reliance Industries Limited   \n",
       "3  Reliance Industries Limited   \n",
       "4  Reliance Industries Limited   \n",
       "\n",
       "   Market capitalization as on March 28, 2024\\n(In lakhs)  \n",
       "0                                       2.010560e+08       \n",
       "1                                       2.010560e+08       \n",
       "2                                       2.010560e+08       \n",
       "3                                       2.010560e+08       \n",
       "4                                       2.010560e+08       "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dividend_rows =  pd.read_csv('data/dividend_rows.csv')\n",
    "dividend_rows['Date'] = pd.to_datetime(dividend_rows['Date'])\n",
    "dividend_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c090dacb-bea9-4a62-9906-1ef610c4d295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\disch\\AppData\\Local\\Temp\\ipykernel_10204\\1269458253.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  analyst_ratings['date'] = pd.to_datetime(analyst_ratings['date'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>author</th>\n",
       "      <th>ltp</th>\n",
       "      <th>target</th>\n",
       "      <th>price_at_reco</th>\n",
       "      <th>upside%</th>\n",
       "      <th>type</th>\n",
       "      <th>pdf_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45319</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>havells-india-ltd</td>\n",
       "      <td>Geojit BNP Paribas\\nReco   Target</td>\n",
       "      <td>1988.05</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>1837.60\\n(8.19%)</td>\n",
       "      <td>17.31</td>\n",
       "      <td>Sell</td>\n",
       "      <td>https://trendlyne.com/get-document/report/pdf/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45320</td>\n",
       "      <td>2024-07-21</td>\n",
       "      <td>havells-india-ltd</td>\n",
       "      <td>Anand Rathi\\nTarget</td>\n",
       "      <td>1988.05</td>\n",
       "      <td>2146.0</td>\n",
       "      <td>1768.50\\n(12.41%)</td>\n",
       "      <td>7.94</td>\n",
       "      <td>Buy</td>\n",
       "      <td>https://trendlyne.com/get-document/report/pdf/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45321</td>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>havells-india-ltd</td>\n",
       "      <td>Keynote Capitals Ltd\\nReco   Target</td>\n",
       "      <td>1988.05</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>1768.50\\n(12.41%)</td>\n",
       "      <td>Target met</td>\n",
       "      <td>Sell</td>\n",
       "      <td>https://trendlyne.com/get-document/report/pdf/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45322</td>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>havells-india-ltd</td>\n",
       "      <td>Prabhudas Lilladhar\\nTarget</td>\n",
       "      <td>1988.05</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>1768.50\\n(12.41%)</td>\n",
       "      <td>Target met</td>\n",
       "      <td>Accumulate</td>\n",
       "      <td>https://trendlyne.com/get-document/report/pdf/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45323</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>havells-india-ltd</td>\n",
       "      <td>BOB Capital Markets Ltd.</td>\n",
       "      <td>1988.05</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>1792.80\\n(10.89%)</td>\n",
       "      <td>Target met</td>\n",
       "      <td>Hold</td>\n",
       "      <td>https://trendlyne.com/get-document/report/pdf/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       date         stock_name  \\\n",
       "0       45319 2024-07-29  havells-india-ltd   \n",
       "1       45320 2024-07-21  havells-india-ltd   \n",
       "2       45321 2024-07-19  havells-india-ltd   \n",
       "3       45322 2024-07-19  havells-india-ltd   \n",
       "4       45323 2024-06-05  havells-india-ltd   \n",
       "\n",
       "                                author      ltp  target      price_at_reco  \\\n",
       "0    Geojit BNP Paribas\\nReco   Target  1988.05  1644.0   1837.60\\n(8.19%)   \n",
       "1                  Anand Rathi\\nTarget  1988.05  2146.0  1768.50\\n(12.41%)   \n",
       "2  Keynote Capitals Ltd\\nReco   Target  1988.05  1720.0  1768.50\\n(12.41%)   \n",
       "3          Prabhudas Lilladhar\\nTarget  1988.05  1976.0  1768.50\\n(12.41%)   \n",
       "4             BOB Capital Markets Ltd.  1988.05  1780.0  1792.80\\n(10.89%)   \n",
       "\n",
       "      upside%        type                                            pdf_url  \n",
       "0       17.31        Sell  https://trendlyne.com/get-document/report/pdf/...  \n",
       "1        7.94         Buy  https://trendlyne.com/get-document/report/pdf/...  \n",
       "2  Target met        Sell  https://trendlyne.com/get-document/report/pdf/...  \n",
       "3  Target met  Accumulate  https://trendlyne.com/get-document/report/pdf/...  \n",
       "4  Target met        Hold  https://trendlyne.com/get-document/report/pdf/...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst_ratings =  pd.read_csv('data/2000_analysts_og.csv')\n",
    "analyst_ratings['date'] = pd.to_datetime(analyst_ratings['date'])\n",
    "analyst_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d79eddf-12fe-4c72-b7fc-f3502ae86aa9",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "774d761d-6152-4ff7-8508-cd742a1386f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
       "       'Description', 'Symbol', 'Company Name',\n",
       "       'Market capitalization as on March 28, 2024\\n(In lakhs)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23f6da1f-1ba1-496b-9e82-cd4c0ff465a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                                           0\n",
       "Open                                                           0\n",
       "High                                                           0\n",
       "Low                                                            0\n",
       "Close                                                          0\n",
       "Adj Close                                                      0\n",
       "Volume                                                    292717\n",
       "Description                                                    0\n",
       "Symbol                                                         0\n",
       "Company Name                                                   0\n",
       "Market capitalization as on March 28, 2024\\n(In lakhs)    103692\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c7e6a6d-187c-48db-a67b-c2e359e6055a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
       "       'Company Name_x', 'Ticker', 'Company Name_y', 'Description', 'Symbol',\n",
       "       'Company Name',\n",
       "       'Market capitalization as on March 28, 2024\\n(In lakhs)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dividend_rows.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c22c67aa-6cdf-413a-902d-d29e2a79b2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                                          0\n",
       "Open                                                          0\n",
       "High                                                      21651\n",
       "Low                                                       21651\n",
       "Close                                                     21651\n",
       "Adj Close                                                 21651\n",
       "Volume                                                    21651\n",
       "Company Name_x                                                0\n",
       "Ticker                                                        0\n",
       "Company Name_y                                                0\n",
       "Description                                                   0\n",
       "Symbol                                                        0\n",
       "Company Name                                                  0\n",
       "Market capitalization as on March 28, 2024\\n(In lakhs)       79\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dividend_rows.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfa148bc-f818-470c-80a4-2c014c58e1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RELIANCE', 'TCS', 'HDFCBANK', ..., 'VISASTEEL', 'GICHSGFIN',\n",
       "       'ALLSEC'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tickers = dividend_rows['Ticker'].unique() \n",
    "unique_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e9513c9-4898-4394-9bf1-6efc5bbc3ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common symbols: 1536\n"
     ]
    }
   ],
   "source": [
    "# Check if the symbols and dates match between datasets - company tickers\n",
    "common_symbols = set(stock_df['Symbol']).intersection(set(dividend_rows['Symbol']))\n",
    "print(f\"Number of common symbols: {len(common_symbols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d797597-04d4-424d-9375-cba8fbfcfd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'stock_name', 'author', 'ltp', 'target',\n",
       "       'price_at_reco', 'upside%', 'type', 'pdf_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst_ratings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc61ae1f-e080-4d7a-a7bc-6649afe9263d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "date               0\n",
       "stock_name         0\n",
       "author             0\n",
       "ltp                0\n",
       "target            72\n",
       "price_at_reco     16\n",
       "upside%          219\n",
       "type              13\n",
       "pdf_url           34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst_ratings.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5919744f-c5a0-428c-a7f6-80d5246b14d2",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "085c784f-513a-4214-ab88-2ebe81d31f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Geojit BNP Paribas' 'Anand Rathi' 'Keynote Capitals Ltd'\n",
      " 'Prabhudas Lilladhar' 'BOB Capital Markets Ltd.'\n",
      " 'ICICI Securities Limited' 'Motilal Oswal' 'ICICI Direct'\n",
      " 'Yes Securities' 'Emkay' 'Way2Wealth' 'Dolat Capital' 'HDFC Securities'\n",
      " 'Reliance Securities' 'Karvy' 'Edelweiss' 'Chola Wealth Direct' 'Bonanza'\n",
      " 'Kotak Securities' 'JM Financial' 'Axis Direct' 'Phillip Capital'\n",
      " 'Ventura' 'GEPL Capital' 'Consensus Share Price Target' 'Sharekhan'\n",
      " 'IDBI Capital' 'Joindre Capital Services'\n",
      " 'Rudra Shares and Stock Brokers Ltd' 'AUM Capital' 'Angel Broking'\n",
      " 'Hem Securities' 'Monarch Networth Capital Limited' 'KRChoksey'\n",
      " 'Ashika Research' 'Systematix Group' 'SMC online' 'Choice India'\n",
      " 'Centrum Broking' 'SBI Securities'\n",
      " 'Asit C Mehta Investment Intermediates' 'Religare']\n"
     ]
    }
   ],
   "source": [
    "# Define a function to clean author names\n",
    "def clean_author_name(author):\n",
    "    # Remove any newline characters and unwanted suffixes\n",
    "    return re.sub(r'\\n.*', '', author).strip()\n",
    "\n",
    "# Apply the cleaning function to the 'author' column using .loc\n",
    "analyst_ratings.loc[:, 'author'] = analyst_ratings['author'].apply(clean_author_name)\n",
    "\n",
    "# Display the cleaned unique author names\n",
    "print(analyst_ratings['author'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b999203-552f-4f5d-a171-b7ed8eb4eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df = stock_df.drop(['Volume', 'Market capitalization as on March 28, 2024\\n(In lakhs)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f07d46b6-7558-48ea-96f9-061fdc63548f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_at_reco</th>\n",
       "      <th>cleaned_price_at_reco</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1837.60\\n(8.19%)</td>\n",
       "      <td>1837.60</td>\n",
       "      <td>(8.19%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1768.50\\n(12.41%)</td>\n",
       "      <td>1768.50</td>\n",
       "      <td>(12.41%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1768.50\\n(12.41%)</td>\n",
       "      <td>1768.50</td>\n",
       "      <td>(12.41%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1768.50\\n(12.41%)</td>\n",
       "      <td>1768.50</td>\n",
       "      <td>(12.41%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792.80\\n(10.89%)</td>\n",
       "      <td>1792.80</td>\n",
       "      <td>(10.89%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>349.00\\n(-47.07%)</td>\n",
       "      <td>349.00</td>\n",
       "      <td>(-47.07%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>261.95\\n(-29.48%)</td>\n",
       "      <td>261.95</td>\n",
       "      <td>(-29.48%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>120.15\\n(53.76%)</td>\n",
       "      <td>120.15</td>\n",
       "      <td>(53.76%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>108.80\\n(69.80%)</td>\n",
       "      <td>108.80</td>\n",
       "      <td>(69.80%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>84.55\\n(118.50%)</td>\n",
       "      <td>84.55</td>\n",
       "      <td>(118.50%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>758 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         price_at_reco  cleaned_price_at_reco percentage\n",
       "0     1837.60\\n(8.19%)                1837.60    (8.19%)\n",
       "1    1768.50\\n(12.41%)                1768.50   (12.41%)\n",
       "2    1768.50\\n(12.41%)                1768.50   (12.41%)\n",
       "3    1768.50\\n(12.41%)                1768.50   (12.41%)\n",
       "4    1792.80\\n(10.89%)                1792.80   (10.89%)\n",
       "..                 ...                    ...        ...\n",
       "753  349.00\\n(-47.07%)                 349.00  (-47.07%)\n",
       "754  261.95\\n(-29.48%)                 261.95  (-29.48%)\n",
       "755   120.15\\n(53.76%)                 120.15   (53.76%)\n",
       "756   108.80\\n(69.80%)                 108.80   (69.80%)\n",
       "757   84.55\\n(118.50%)                  84.55  (118.50%)\n",
       "\n",
       "[758 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_price_at_reco(price):\n",
    "    percentage = None  # Initialize percentage as None\n",
    "\n",
    "    # Check if the price is a string\n",
    "    if isinstance(price, str):\n",
    "        # Split the string by newline\n",
    "        parts = price.split('\\n')\n",
    "        \n",
    "        # Check if we have at least two parts\n",
    "        if len(parts) >= 2:\n",
    "            # Take the first part as price and second as percentage\n",
    "            price = parts[0]\n",
    "            percentage = parts[1]\n",
    "            \n",
    "        # Attempt to convert to numeric, ignoring any errors\n",
    "        price = pd.to_numeric(price, errors='coerce')\n",
    "    \n",
    "    return price, percentage\n",
    "    \n",
    "# Apply the cleaning function to the 'price_at_reco' column and collect results\n",
    "analyst_ratings[['cleaned_price_at_reco', 'percentage']] = analyst_ratings['price_at_reco'].apply(\n",
    "    lambda x: pd.Series(clean_price_at_reco(x))\n",
    ")\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "analyst_ratings[['price_at_reco', 'cleaned_price_at_reco', 'percentage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e62efa29-72c0-494e-ac5b-aadb2c04e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'price_at_reco' and 'target' to extract numeric values\n",
    "analyst_ratings['cleaned_price_at_reco'] = analyst_ratings['cleaned_price_at_reco'].astype(float)\n",
    "analyst_ratings['target'] = analyst_ratings['target'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "204a5d0f-da4c-495b-8ff4-0d5ea76573ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_price_at_reco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1644.0</td>\n",
       "      <td>1837.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2146.0</td>\n",
       "      <td>1768.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1720.0</td>\n",
       "      <td>1768.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976.0</td>\n",
       "      <td>1768.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1780.0</td>\n",
       "      <td>1792.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>410.0</td>\n",
       "      <td>349.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>362.0</td>\n",
       "      <td>261.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>144.0</td>\n",
       "      <td>120.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>139.0</td>\n",
       "      <td>108.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>103.0</td>\n",
       "      <td>84.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>758 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  cleaned_price_at_reco\n",
       "0    1644.0                1837.60\n",
       "1    2146.0                1768.50\n",
       "2    1720.0                1768.50\n",
       "3    1976.0                1768.50\n",
       "4    1780.0                1792.80\n",
       "..      ...                    ...\n",
       "753   410.0                 349.00\n",
       "754   362.0                 261.95\n",
       "755   144.0                 120.15\n",
       "756   139.0                 108.80\n",
       "757   103.0                  84.55\n",
       "\n",
       "[758 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#difference between target and price at recommendation - which defines upside% whether target was met or not\n",
    "analyst_ratings[['target','cleaned_price_at_reco']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d3040f-d4cf-41a4-b6cf-bbf0efd420db",
   "metadata": {},
   "source": [
    "# Output Variable 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39ca47b1-710b-4d38-8e5e-27c280cbcc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected return\n",
    "analyst_ratings['expected_return'] = ((analyst_ratings['target'] - analyst_ratings['cleaned_price_at_reco']) / analyst_ratings['cleaned_price_at_reco']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "061e6b11-bd07-4aa3-a31c-46600cae795b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>author</th>\n",
       "      <th>ltp</th>\n",
       "      <th>target</th>\n",
       "      <th>price_at_reco</th>\n",
       "      <th>upside%</th>\n",
       "      <th>type</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>cleaned_price_at_reco</th>\n",
       "      <th>percentage</th>\n",
       "      <th>expected_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45319</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>havells-india-ltd</td>\n",
       "      <td>Geojit BNP Paribas</td>\n",
       "      <td>1988.05</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>1837.60\\n(8.19%)</td>\n",
       "      <td>17.31</td>\n",
       "      <td>Sell</td>\n",
       "      <td>https://trendlyne.com/get-document/report/pdf/...</td>\n",
       "      <td>1837.6</td>\n",
       "      <td>(8.19%)</td>\n",
       "      <td>-10.535481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45320</td>\n",
       "      <td>2024-07-21</td>\n",
       "      <td>havells-india-ltd</td>\n",
       "      <td>Anand Rathi</td>\n",
       "      <td>1988.05</td>\n",
       "      <td>2146.0</td>\n",
       "      <td>1768.50\\n(12.41%)</td>\n",
       "      <td>7.94</td>\n",
       "      <td>Buy</td>\n",
       "      <td>https://trendlyne.com/get-document/report/pdf/...</td>\n",
       "      <td>1768.5</td>\n",
       "      <td>(12.41%)</td>\n",
       "      <td>21.345773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45321</td>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>havells-india-ltd</td>\n",
       "      <td>Keynote Capitals Ltd</td>\n",
       "      <td>1988.05</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>1768.50\\n(12.41%)</td>\n",
       "      <td>Target met</td>\n",
       "      <td>Sell</td>\n",
       "      <td>https://trendlyne.com/get-document/report/pdf/...</td>\n",
       "      <td>1768.5</td>\n",
       "      <td>(12.41%)</td>\n",
       "      <td>-2.742437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45322</td>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>havells-india-ltd</td>\n",
       "      <td>Prabhudas Lilladhar</td>\n",
       "      <td>1988.05</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>1768.50\\n(12.41%)</td>\n",
       "      <td>Target met</td>\n",
       "      <td>Accumulate</td>\n",
       "      <td>https://trendlyne.com/get-document/report/pdf/...</td>\n",
       "      <td>1768.5</td>\n",
       "      <td>(12.41%)</td>\n",
       "      <td>11.733107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45323</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>havells-india-ltd</td>\n",
       "      <td>BOB Capital Markets Ltd.</td>\n",
       "      <td>1988.05</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>1792.80\\n(10.89%)</td>\n",
       "      <td>Target met</td>\n",
       "      <td>Hold</td>\n",
       "      <td>https://trendlyne.com/get-document/report/pdf/...</td>\n",
       "      <td>1792.8</td>\n",
       "      <td>(10.89%)</td>\n",
       "      <td>-0.713967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       date         stock_name                    author  \\\n",
       "0       45319 2024-07-29  havells-india-ltd        Geojit BNP Paribas   \n",
       "1       45320 2024-07-21  havells-india-ltd               Anand Rathi   \n",
       "2       45321 2024-07-19  havells-india-ltd      Keynote Capitals Ltd   \n",
       "3       45322 2024-07-19  havells-india-ltd       Prabhudas Lilladhar   \n",
       "4       45323 2024-06-05  havells-india-ltd  BOB Capital Markets Ltd.   \n",
       "\n",
       "       ltp  target      price_at_reco     upside%        type  \\\n",
       "0  1988.05  1644.0   1837.60\\n(8.19%)       17.31        Sell   \n",
       "1  1988.05  2146.0  1768.50\\n(12.41%)        7.94         Buy   \n",
       "2  1988.05  1720.0  1768.50\\n(12.41%)  Target met        Sell   \n",
       "3  1988.05  1976.0  1768.50\\n(12.41%)  Target met  Accumulate   \n",
       "4  1988.05  1780.0  1792.80\\n(10.89%)  Target met        Hold   \n",
       "\n",
       "                                             pdf_url  cleaned_price_at_reco  \\\n",
       "0  https://trendlyne.com/get-document/report/pdf/...                 1837.6   \n",
       "1  https://trendlyne.com/get-document/report/pdf/...                 1768.5   \n",
       "2  https://trendlyne.com/get-document/report/pdf/...                 1768.5   \n",
       "3  https://trendlyne.com/get-document/report/pdf/...                 1768.5   \n",
       "4  https://trendlyne.com/get-document/report/pdf/...                 1792.8   \n",
       "\n",
       "  percentage  expected_return  \n",
       "0    (8.19%)       -10.535481  \n",
       "1   (12.41%)        21.345773  \n",
       "2   (12.41%)        -2.742437  \n",
       "3   (12.41%)        11.733107  \n",
       "4   (10.89%)        -0.713967  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41f37a2d-33f3-479b-b963-55158fc8cace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape (1973, 5000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 758/758 [00:04<00:00, 155.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Filter the DataFrame for the date range\n",
    "df_2019 = stock_df[(stock_df['Date'] >= '1900-01-01') & (stock_df['Date'] <= '2024-12-31')]\n",
    "\n",
    "# Prepare company names for TF-IDF matching\n",
    "company_names = [x.lower() for x in stock_df['Company Name'].unique().tolist()]\n",
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4), max_features=5000)  # Character-based TF-IDF\n",
    "tfidf_matrix = vectorizer.fit_transform(company_names)\n",
    "\n",
    "print(\"Matrix shape\", tfidf_matrix.shape)\n",
    "\n",
    "# Function to get the best match using cosine similarity\n",
    "def get_closest_company_name(input_name, company_names, tfidf_matrix, vectorizer):\n",
    "    input_tfidf = vectorizer.transform([input_name.lower()])\n",
    "    cosine_similarities = cosine_similarity(input_tfidf, tfidf_matrix).flatten()\n",
    "    best_match_idx = cosine_similarities.argmax()\n",
    "    best_match_score = cosine_similarities[best_match_idx]\n",
    "    return company_names[best_match_idx] if best_match_score > 0.5 else None  # Threshold of 0.5 for similarity\n",
    "\n",
    "# Apply TF-IDF matching with tqdm for progress visualization\n",
    "tqdm.pandas()  # Initialize tqdm with pandas\n",
    "analyst_ratings['matched_company_name'] = analyst_ratings['stock_name'].progress_apply(\n",
    "    lambda x: get_closest_company_name(x, company_names, tfidf_matrix, vectorizer)\n",
    ")\n",
    "\n",
    "# Create a mapping of matched company names to symbols\n",
    "symbol_map = stock_df[['Company Name', 'Symbol']].drop_duplicates()\n",
    "symbol_map['Company Name'] = symbol_map['Company Name'].str.lower()\n",
    "analyst_ratings = pd.merge(analyst_ratings, symbol_map, left_on='matched_company_name', right_on='Company Name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e7d625f-834d-4036-84d3-fcd01f2e6edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0       date           stock_name                    author  \\\n",
      "0         45319 2024-07-29    havells-india-ltd        Geojit BNP Paribas   \n",
      "1         45320 2024-07-21    havells-india-ltd               Anand Rathi   \n",
      "2         45321 2024-07-19    havells-india-ltd      Keynote Capitals Ltd   \n",
      "3         45322 2024-07-19    havells-india-ltd       Prabhudas Lilladhar   \n",
      "4         45323 2024-06-05    havells-india-ltd  BOB Capital Markets Ltd.   \n",
      "..          ...        ...                  ...                       ...   \n",
      "753       46072 2017-11-08  rain-industries-ltd               AUM Capital   \n",
      "754       46073 2017-11-01  rain-industries-ltd             Motilal Oswal   \n",
      "755       46074 2017-08-14  rain-industries-ltd              IDBI Capital   \n",
      "756       46075 2017-05-08  rain-industries-ltd              IDBI Capital   \n",
      "757       46076 2017-02-27  rain-industries-ltd              IDBI Capital   \n",
      "\n",
      "         ltp  target      price_at_reco     upside%        type  \\\n",
      "0    1988.05  1644.0   1837.60\\n(8.19%)       17.31        Sell   \n",
      "1    1988.05  2146.0  1768.50\\n(12.41%)        7.94         Buy   \n",
      "2    1988.05  1720.0  1768.50\\n(12.41%)  Target met        Sell   \n",
      "3    1988.05  1976.0  1768.50\\n(12.41%)  Target met  Accumulate   \n",
      "4    1988.05  1780.0  1792.80\\n(10.89%)  Target met        Hold   \n",
      "..       ...     ...                ...         ...         ...   \n",
      "753   184.74   410.0  349.00\\n(-47.07%)  Target met         Buy   \n",
      "754   184.74   362.0  261.95\\n(-29.48%)  Target met         Buy   \n",
      "755   184.74   144.0   120.15\\n(53.76%)  Target met         Buy   \n",
      "756   184.74   139.0   108.80\\n(69.80%)  Target met         Buy   \n",
      "757   184.74   103.0   84.55\\n(118.50%)  Target met         Buy   \n",
      "\n",
      "                                               pdf_url  cleaned_price_at_reco  \\\n",
      "0    https://trendlyne.com/get-document/report/pdf/...                1837.60   \n",
      "1    https://trendlyne.com/get-document/report/pdf/...                1768.50   \n",
      "2    https://trendlyne.com/get-document/report/pdf/...                1768.50   \n",
      "3    https://trendlyne.com/get-document/report/pdf/...                1768.50   \n",
      "4    https://trendlyne.com/get-document/report/pdf/...                1792.80   \n",
      "..                                                 ...                    ...   \n",
      "753  https://trendlyne.com/get-document/report/pdf/...                 349.00   \n",
      "754  https://trendlyne.com/get-document/report/pdf/...                 261.95   \n",
      "755  https://trendlyne.com/get-document/report/pdf/...                 120.15   \n",
      "756  https://trendlyne.com/get-document/report/pdf/...                 108.80   \n",
      "757  https://trendlyne.com/get-document/report/pdf/...                  84.55   \n",
      "\n",
      "    percentage  expected_return     matched_company_name  \\\n",
      "0      (8.19%)       -10.535481    havells india limited   \n",
      "1     (12.41%)        21.345773    havells india limited   \n",
      "2     (12.41%)        -2.742437    havells india limited   \n",
      "3     (12.41%)        11.733107    havells india limited   \n",
      "4     (10.89%)        -0.713967    havells india limited   \n",
      "..         ...              ...                      ...   \n",
      "753  (-47.07%)        17.478510  rain industries limited   \n",
      "754  (-29.48%)        38.194312  rain industries limited   \n",
      "755   (53.76%)        19.850187  rain industries limited   \n",
      "756   (69.80%)        27.757353  rain industries limited   \n",
      "757  (118.50%)        21.821407  rain industries limited   \n",
      "\n",
      "                Company Name   Symbol  \n",
      "0      havells india limited  HAVELLS  \n",
      "1      havells india limited  HAVELLS  \n",
      "2      havells india limited  HAVELLS  \n",
      "3      havells india limited  HAVELLS  \n",
      "4      havells india limited  HAVELLS  \n",
      "..                       ...      ...  \n",
      "753  rain industries limited     RAIN  \n",
      "754  rain industries limited     RAIN  \n",
      "755  rain industries limited     RAIN  \n",
      "756  rain industries limited     RAIN  \n",
      "757  rain industries limited     RAIN  \n",
      "\n",
      "[758 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "print(analyst_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6110e527-a5e5-4d0b-9f5d-4b9478fc59bc",
   "metadata": {},
   "source": [
    "## Import *predict_n_day_return* Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1af3be1-e817-4c8b-82cb-6ed835698fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current directory of the notebook\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# Append the directory of script\n",
    "sys.path.append(os.path.join(current_dir, 'Project-1'))\n",
    "\n",
    "# call predict_n_day_return function\n",
    "from nday_stockprediction import predict_n_day_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d786c32-8221-4a58-852e-2d71ee516a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|▏                                                                     | 2/758 [00:07<49:02,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2024-07-21 00:00:00 not found. Using nearest date: 2024-07-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   1%|█                                                                    | 11/758 [00:42<48:49,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2024-05-01 00:00:00 not found. Using nearest date: 2024-05-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|█                                                                    | 12/758 [00:46<48:13,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2024-05-01 00:00:00 not found. Using nearest date: 2024-05-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   7%|████▉                                                                | 54/758 [03:30<46:04,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2022-05-07 00:00:00 not found. Using nearest date: 2022-05-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   7%|█████                                                                | 55/758 [03:34<45:28,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2022-05-07 00:00:00 not found. Using nearest date: 2022-05-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   7%|█████                                                                | 56/758 [03:38<45:20,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2022-05-07 00:00:00 not found. Using nearest date: 2022-05-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   8%|█████▌                                                               | 61/758 [03:56<44:11,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2022-01-23 00:00:00 not found. Using nearest date: 2022-01-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   8%|█████▋                                                               | 62/758 [04:00<44:03,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2022-01-22 00:00:00 not found. Using nearest date: 2022-01-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   9%|██████▌                                                              | 72/758 [04:39<44:13,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2021-05-22 00:00:00 not found. Using nearest date: 2021-05-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  10%|██████▋                                                              | 73/758 [04:43<44:10,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2021-05-22 00:00:00 not found. Using nearest date: 2021-05-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  18%|████████████▎                                                       | 137/758 [08:47<39:44,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2018-10-18 00:00:00 not found. Using nearest date: 2018-10-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  19%|█████████████                                                       | 146/758 [09:22<38:57,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2018-07-21 00:00:00 not found. Using nearest date: 2018-07-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  21%|█████████████▉                                                      | 156/758 [10:00<37:55,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2018-05-12 00:00:00 not found. Using nearest date: 2018-05-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  26%|█████████████████▍                                                  | 194/758 [12:24<35:30,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2016-07-24 00:00:00 not found. Using nearest date: 2016-07-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  29%|████████████████████                                                | 223/758 [14:14<33:46,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for HONAUT on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  30%|████████████████████▋                                               | 230/758 [14:41<34:04,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for VSSL on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  31%|█████████████████████                                               | 235/758 [15:00<33:13,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2022-05-03 00:00:00 not found. Using nearest date: 2022-05-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  32%|█████████████████████▌                                              | 240/758 [15:19<32:36,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2021-05-16 00:00:00 not found. Using nearest date: 2021-05-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  33%|██████████████████████▎                                             | 249/758 [15:53<32:05,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for JTEKTINDIA on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  33%|██████████████████████▌                                             | 251/758 [16:00<31:59,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for PREMIER on 2024-08-26 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-08-26 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  33%|██████████████████████▌                                             | 252/758 [16:04<31:51,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for POLYMED on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  34%|██████████████████████▉                                             | 256/758 [16:19<31:29,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2022-11-08 00:00:00 not found. Using nearest date: 2022-11-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  35%|███████████████████████▌                                            | 263/758 [16:46<31:19,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for PENIND on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  35%|████████████████████████                                            | 268/758 [17:05<31:55,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for JINDALSTEL on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  36%|████████████████████████▊                                           | 276/758 [17:36<30:48,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2024-02-03 00:00:00 not found. Using nearest date: 2024-02-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  37%|█████████████████████████                                           | 280/758 [17:51<30:24,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2023-08-13 00:00:00 not found. Using nearest date: 2023-08-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  38%|█████████████████████████▉                                          | 289/758 [18:26<29:59,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2022-07-16 00:00:00 not found. Using nearest date: 2022-07-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  42%|████████████████████████████▊                                       | 321/758 [20:27<27:33,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2019-08-18 00:00:00 not found. Using nearest date: 2019-08-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  43%|█████████████████████████████▏                                      | 325/758 [20:43<27:54,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2019-02-02 00:00:00 not found. Using nearest date: 2019-02-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  45%|██████████████████████████████▍                                     | 339/758 [21:37<27:18,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2016-09-10 00:00:00 not found. Using nearest date: 2016-09-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  45%|██████████████████████████████▋                                     | 342/758 [21:48<26:39,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for ACLGATI on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  45%|██████████████████████████████▊                                     | 343/758 [21:52<26:25,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for ACLGATI on 2024-08-07 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-08-07 00:00:00 not found. Using nearest date: 2024-07-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  49%|█████████████████████████████████                                   | 369/758 [23:30<24:30,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for ROSSARI on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  49%|█████████████████████████████████▍                                  | 373/758 [23:46<24:10,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2024-05-01 00:00:00 not found. Using nearest date: 2024-05-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  50%|█████████████████████████████████▊                                  | 377/758 [24:01<23:52,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2023-10-24 00:00:00 not found. Using nearest date: 2023-10-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  50%|█████████████████████████████████▉                                  | 378/758 [24:04<23:45,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2023-10-24 00:00:00 not found. Using nearest date: 2023-10-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  52%|███████████████████████████████████▌                                | 397/758 [25:16<22:52,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2020-11-16 00:00:00 not found. Using nearest date: 2020-11-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  53%|███████████████████████████████████▊                                | 399/758 [25:24<22:47,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2020-07-13 00:00:00 not found. Using nearest date: 2020-07-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  53%|███████████████████████████████████▉                                | 400/758 [25:28<22:37,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2020-07-13 00:00:00 not found. Using nearest date: 2020-07-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  53%|███████████████████████████████████▉                                | 401/758 [25:32<22:37,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2020-07-11 00:00:00 not found. Using nearest date: 2020-07-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  53%|████████████████████████████████████                                | 402/758 [25:36<23:39,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for DHANUKA on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  53%|████████████████████████████████████▏                               | 403/758 [25:40<23:15,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for DHANUKA on 2024-08-05 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-08-05 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  55%|█████████████████████████████████████▋                              | 420/758 [26:45<21:37,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2021-07-31 00:00:00 not found. Using nearest date: 2021-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  57%|██████████████████████████████████████▊                             | 432/758 [27:30<20:31,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2020-05-17 00:00:00 not found. Using nearest date: 2020-05-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  58%|███████████████████████████████████████▎                            | 438/758 [27:52<19:57,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2019-02-13 00:00:00 not found. Using nearest date: 2019-02-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  60%|█████████████████████████████████████████                           | 458/758 [29:08<19:00,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for LTIM on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  61%|█████████████████████████████████████████▏                          | 459/758 [29:12<19:04,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for LTIM on 2024-07-31 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-07-31 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  65%|████████████████████████████████████████████▍                       | 496/758 [31:31<16:23,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2023-02-25 00:00:00 not found. Using nearest date: 2023-02-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  66%|████████████████████████████████████████████▊                       | 499/758 [31:42<16:12,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2023-01-22 00:00:00 not found. Using nearest date: 2023-01-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  66%|█████████████████████████████████████████████                       | 503/758 [31:57<16:01,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2022-10-16 00:00:00 not found. Using nearest date: 2022-10-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  66%|█████████████████████████████████████████████▏                      | 504/758 [32:01<15:56,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2022-10-16 00:00:00 not found. Using nearest date: 2022-10-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  67%|█████████████████████████████████████████████▎                      | 505/758 [32:06<16:51,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2022-07-16 00:00:00 not found. Using nearest date: 2022-07-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  70%|███████████████████████████████████████████████▎                    | 528/758 [33:36<16:13,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2021-07-17 00:00:00 not found. Using nearest date: 2021-07-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  70%|███████████████████████████████████████████████▍                    | 529/758 [33:40<15:36,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2021-07-17 00:00:00 not found. Using nearest date: 2021-07-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  76%|███████████████████████████████████████████████████▍                | 573/758 [36:29<11:51,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2019-10-19 00:00:00 not found. Using nearest date: 2019-10-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  76%|███████████████████████████████████████████████████▌                | 575/758 [36:36<11:45,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2019-07-20 00:00:00 not found. Using nearest date: 2019-07-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  76%|███████████████████████████████████████████████████▋                | 576/758 [36:40<11:48,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2019-07-20 00:00:00 not found. Using nearest date: 2019-07-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  77%|████████████████████████████████████████████████████                | 580/758 [36:56<11:23,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2019-05-05 00:00:00 not found. Using nearest date: 2019-05-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  77%|████████████████████████████████████████████████████▋               | 587/758 [37:22<10:50,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2019-01-19 00:00:00 not found. Using nearest date: 2019-01-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  79%|█████████████████████████████████████████████████████▊              | 600/758 [38:12<09:57,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2018-01-26 00:00:00 not found. Using nearest date: 2018-01-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  80%|██████████████████████████████████████████████████████▋             | 610/758 [38:50<09:21,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2016-07-11 00:00:00 not found. Using nearest date: 2016-07-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  81%|██████████████████████████████████████████████████████▊             | 611/758 [38:53<09:18,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2016-07-09 00:00:00 not found. Using nearest date: 2016-07-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  81%|██████████████████████████████████████████████████████▉             | 612/758 [38:57<09:13,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2016-07-08 00:00:00 not found. Using nearest date: 2016-07-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  81%|██████████████████████████████████████████████████████▉             | 613/758 [39:01<09:08,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2016-07-08 00:00:00 not found. Using nearest date: 2016-07-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  81%|███████████████████████████████████████████████████████             | 614/758 [39:05<09:04,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2016-07-05 00:00:00 not found. Using nearest date: 2016-07-21 00:00:00\n",
      "Reference date 2018-06-23 00:00:00 not found. Using nearest date: 2016-07-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  82%|███████████████████████████████████████████████████████▊            | 622/758 [39:32<08:26,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for RVNL on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  83%|████████████████████████████████████████████████████████▎           | 628/758 [39:54<08:07,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for BOROLTD on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  85%|██████████████████████████████████████████████████████████▏         | 648/758 [40:25<01:09,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2023-11-15 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2023-02-14 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2022-08-13 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2022-05-31 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2022-01-28 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2021-11-08 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2021-09-29 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2021-08-16 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2021-02-16 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2020-12-17 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2018-05-31 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2017-11-09 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2017-05-12 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2016-12-10 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2024-06-12 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2024-09-04 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2024-08-20 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2024-05-22 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2024-05-21 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n",
      "Reference date 2024-05-21 00:00:00 not found. Using nearest date: 2021-08-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  87%|███████████████████████████████████████████████████████████         | 659/758 [40:33<00:47,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for GOCOLORS on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  87%|███████████████████████████████████████████████████████████▍        | 663/758 [40:48<01:58,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2024-05-04 00:00:00 not found. Using nearest date: 2024-05-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  88%|███████████████████████████████████████████████████████████▋        | 665/758 [40:56<02:38,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2023-05-06 00:00:00 not found. Using nearest date: 2023-05-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  89%|████████████████████████████████████████████████████████████▏       | 671/758 [41:15<04:20,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2021-11-16 00:00:00 not found. Using nearest date: 2021-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  89%|████████████████████████████████████████████████████████████▎       | 672/758 [41:19<04:32,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2021-11-16 00:00:00 not found. Using nearest date: 2021-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  89%|████████████████████████████████████████████████████████████▎       | 673/758 [41:23<04:44,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2021-11-16 00:00:00 not found. Using nearest date: 2021-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  89%|████████████████████████████████████████████████████████████▍       | 674/758 [41:26<04:51,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2021-11-16 00:00:00 not found. Using nearest date: 2021-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  89%|████████████████████████████████████████████████████████████▌       | 675/758 [41:30<04:55,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for CAMLINFINE on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  89%|████████████████████████████████████████████████████████████▋       | 676/758 [41:34<04:57,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for CAMLINFINE on 2024-08-13 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-08-13 00:00:00 not found. Using nearest date: 2024-07-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  91%|█████████████████████████████████████████████████████████████▉      | 690/758 [42:29<04:22,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2018-02-17 00:00:00 not found. Using nearest date: 2018-02-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|██████████████████████████████████████████████████████████████▎     | 695/758 [42:48<04:01,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for PGEL on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|██████████████████████████████████████████████████████████████▌     | 698/758 [42:59<03:48,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for NRBBEARING on 2024-09-14 00:00:00: Insufficient data to determine d+1.\n",
      "Reference date 2024-09-14 00:00:00 not found. Using nearest date: 2024-07-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  94%|███████████████████████████████████████████████████████████████▌    | 709/758 [43:41<03:08,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2019-02-13 00:00:00 not found. Using nearest date: 2019-02-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  94%|████████████████████████████████████████████████████████████████    | 714/758 [44:01<02:47,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference date 2018-11-03 00:00:00 not found. Using nearest date: 2018-11-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|████████████████████████████████████████████████████████████████████| 758/758 [46:49<00:00,  3.71s/it]\n"
     ]
    }
   ],
   "source": [
    "# Function to get the nearest available date in stock data if the exact date is missing\n",
    "def get_nearest_date(stock_data, reference_date):\n",
    "    stock_data = stock_data.copy()\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'])  \n",
    "    reference_date = pd.to_datetime(reference_date)\n",
    "    \n",
    "    if reference_date in stock_data['Date'].values:\n",
    "        return reference_date  # Exact match found\n",
    "    else:\n",
    "        # Find the nearest available date\n",
    "        closest_date = stock_data.loc[stock_data['Date'].sub(reference_date).abs().idxmin(), 'Date']\n",
    "        return closest_date\n",
    "\n",
    "# Loop through each row of the analyst ratings with a progress bar\n",
    "for index, row in tqdm(analyst_ratings.iterrows(), total=analyst_ratings.shape[0], desc=\"Processing\"):\n",
    "    matched_company = row['matched_company_name']  # Refer to the matched company name in the dataframe\n",
    "    \n",
    "    if matched_company:\n",
    "        # Get the ticker corresponding to the matched company name\n",
    "        matched_ticker = stock_df[stock_df['Company Name'].str.lower() == matched_company]['Symbol'].iloc[0]\n",
    "    else:\n",
    "        matched_ticker = None  # No matching company found\n",
    "    \n",
    "    n_days = 5  # Set the number of days for predicting return\n",
    "    \n",
    "    # Only call the function if a ticker was found\n",
    "    if matched_ticker:\n",
    "        try:\n",
    "            # Get stock data for the matched ticker\n",
    "            stock_data = stock_df.loc[stock_df['Symbol'] == matched_ticker].copy()  # Use .copy() to avoid warnings\n",
    "            \n",
    "            # Get the nearest available date if the reference date is not found\n",
    "            nearest_date = get_nearest_date(stock_data, row['date'])\n",
    "            \n",
    "            # Call the prediction function with the nearest available date\n",
    "            _, _, total_return, _, _, _ = predict_n_day_return(matched_ticker, nearest_date, n_days, stock_df, dividend_rows)\n",
    "            analyst_ratings.loc[index, 'actual_return'] = total_return  # Use .loc to set the value\n",
    "        \n",
    "        except Exception as e:\n",
    "            analyst_ratings.loc[index, 'actual_return'] = None  # Store None if there's an error\n",
    "            tqdm.write(f\"Error for {matched_ticker} on {row['date']}: {e}\")\n",
    "    else:\n",
    "        analyst_ratings.loc[index, 'actual_return'] = None  # No ticker found, store None\n",
    "    \n",
    "    # Print a warning if the nearest date is not the same as the reference date\n",
    "    if nearest_date != row['date']:\n",
    "        tqdm.write(f\"Reference date {row['date']} not found. Using nearest date: {nearest_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f731bcd2-c3cc-4ec8-ac7b-72f19f0fa1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_keywords = {\n",
    "    'Finance': ['bank', 'financial', 'insurance', 'capital', 'investment', 'wealth', 'lending', 'asset management', 'mutual fund', 'securities', 'credit', 'equity', 'stock exchange', 'private equity', 'venture capital'],\n",
    "    \n",
    "    'Technology': ['tech', 'software', 'IT', 'digital', 'cloud', 'data', 'artificial intelligence', 'AI', 'machine learning', 'hardware', 'blockchain', 'cybersecurity', 'semiconductor', 'saas', 'paas', 'technology services', 'internet', 'networking'],\n",
    "    \n",
    "    'Healthcare': ['pharma', 'biotech', 'medical', 'healthcare', 'hospital', 'clinical', 'diagnostics', 'life sciences', 'medtech', 'wellness', 'drug', 'therapy', 'genomics', 'vaccines', 'biopharma'],\n",
    "    \n",
    "    'Manufacturing': ['steel', 'cement', 'construction', 'engineering', 'manufacturing', 'machinery', 'industrial', 'fabrication', 'metals', 'automotive', 'tools', 'aerospace', 'assembly', 'chemicals', 'plastics', 'production'],\n",
    "    \n",
    "    'Energy': ['oil', 'energy', 'gas', 'power', 'coal', 'electricity', 'solar', 'renewable', 'wind', 'hydro', 'nuclear', 'fossil fuels', 'mining', 'petroleum', 'green energy', 'battery'],\n",
    "    \n",
    "    'Consumer Goods': ['consumer', 'retail', 'fashion', 'apparel', 'food', 'beverage', 'fmcg', 'personal care', 'household', 'luxury', 'ecommerce', 'cosmetics', 'home appliances', 'groceries', 'sportswear', 'furniture'],\n",
    "    \n",
    "    'Telecommunications': ['telecom', 'wireless', 'broadband', 'satellite', 'mobile', 'network', 'fiber', 'telecommunication services', 'cellular', '5G', 'communication', 'ISP'],\n",
    "    \n",
    "    'Utilities': ['water', 'electric', 'gas distribution', 'utilities', 'waste management', 'public services', 'sanitation', 'power grid'],\n",
    "    \n",
    "    'Real Estate': ['real estate', 'property', 'construction', 'housing', 'commercial real estate', 'residential', 'mortgage', 'land development', 'realty', 'leasing', 'brokerage', 'facility management', 'rental'],\n",
    "    \n",
    "    'Transportation': ['logistics', 'shipping', 'transportation', 'rail', 'trucking', 'freight', 'airlines', 'aviation', 'maritime', 'delivery', 'supply chain', 'public transport', 'cargo', 'transport services'],\n",
    "    \n",
    "    'Media & Entertainment': ['media', 'entertainment', 'film', 'television', 'music', 'broadcast', 'news', 'publishing', 'streaming', 'advertising', 'social media', 'gaming', 'content creation'],\n",
    "    \n",
    "    'Agriculture': ['agriculture', 'farming', 'crop', 'livestock', 'dairy', 'agribusiness', 'fertilizers', 'agrochemicals', 'forestry', 'horticulture', 'fisheries', 'seed', 'organic farming'],\n",
    "    \n",
    "    'Retail': ['retail', 'wholesale', 'department store', 'grocery', 'mall', 'shopping', 'online store', 'boutique', 'supermarket', 'convenience store']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecb73112-9131-4352-b8a5-cecac09c704f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1973/1973 [00:00<00:00, 9847.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Symbol                       Company Name  \\\n",
      "0          RELIANCE        Reliance Industries Limited   \n",
      "5451            TCS  Tata Consultancy Services Limited   \n",
      "10903      HDFCBANK                  HDFC Bank Limited   \n",
      "16357     ICICIBANK                 ICICI Bank Limited   \n",
      "21808    BHARTIARTL              Bharti Airtel Limited   \n",
      "...             ...                                ...   \n",
      "6793823     GULPOLY            Gulshan Polyols Limited   \n",
      "6796162  ASIANTILES        Asian Granito India Limited   \n",
      "6800330   VISASTEEL                 Visa Steel Limited   \n",
      "6804854   GICHSGFIN        GIC Housing Finance Limited   \n",
      "6810303      ALLSEC        Allsec Technologies Limited   \n",
      "\n",
      "                                               Description         Sector  \n",
      "0        Reliance Industries Limited engages in hydroca...        Finance  \n",
      "5451     Tata Consultancy Services Limited provides inf...        Finance  \n",
      "10903    HDFC Bank Limited engages in the provision of ...        Finance  \n",
      "16357    ICICI Bank Limited provides various banking pr...        Finance  \n",
      "21808    Bharti Airtel Limited operates as a telecommun...     Technology  \n",
      "...                                                    ...            ...  \n",
      "6793823  Gulshan Polyols Limited engages in the mineral...     Healthcare  \n",
      "6796162  Asian Granito India Limited, together with its...  Manufacturing  \n",
      "6800330  VISA Steel Limited, together with its subsidia...  Manufacturing  \n",
      "6804854  GIC Housing Finance Limited provides housing f...  Manufacturing  \n",
      "6810303  Allsec Technologies Limited provides business ...        Finance  \n",
      "\n",
      "[1973 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Function to identify sector based on description\n",
    "def identify_sector(description):\n",
    "    description = description.lower()  # Convert to lowercase for case-insensitive matching\n",
    "    for sector, keywords in industry_keywords.items():\n",
    "        if any(keyword in description for keyword in keywords):\n",
    "            return sector\n",
    "    return 'Unknown'  # Return 'Unknown' if no match is found\n",
    "\n",
    "# Create a new DataFrame with unique companies based on 'Symbol'\n",
    "unique_companies_df = stock_df.drop_duplicates(subset=['Symbol']).copy()\n",
    "\n",
    "# Apply sector identification on the unique companies\n",
    "unique_companies_df['Sector'] = unique_companies_df['Description'].progress_apply(identify_sector)\n",
    "\n",
    "# Display the updated DataFrame with unique entries and their sector\n",
    "print(unique_companies_df[['Symbol', 'Company Name', 'Description', 'Sector']])\n",
    "\n",
    "# If needed, you can save this to a new DataFrame, e.g., `unique_sector_df`, without affecting `stock_df`\n",
    "unique_sector_df = unique_companies_df[['Symbol', 'Company Name', 'Description', 'Sector']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f92c1e05-82f8-4c68-a061-fe3ef9c1d1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       date         stock_name                    author  \\\n",
      "0       45319 2024-07-29  havells-india-ltd        Geojit BNP Paribas   \n",
      "1       45320 2024-07-21  havells-india-ltd               Anand Rathi   \n",
      "2       45321 2024-07-19  havells-india-ltd      Keynote Capitals Ltd   \n",
      "3       45322 2024-07-19  havells-india-ltd       Prabhudas Lilladhar   \n",
      "4       45323 2024-06-05  havells-india-ltd  BOB Capital Markets Ltd.   \n",
      "\n",
      "       ltp  target      price_at_reco     upside%        type  \\\n",
      "0  1988.05  1644.0   1837.60\\n(8.19%)       17.31        Sell   \n",
      "1  1988.05  2146.0  1768.50\\n(12.41%)        7.94         Buy   \n",
      "2  1988.05  1720.0  1768.50\\n(12.41%)  Target met        Sell   \n",
      "3  1988.05  1976.0  1768.50\\n(12.41%)  Target met  Accumulate   \n",
      "4  1988.05  1780.0  1792.80\\n(10.89%)  Target met        Hold   \n",
      "\n",
      "                                             pdf_url  cleaned_price_at_reco  \\\n",
      "0  https://trendlyne.com/get-document/report/pdf/...                 1837.6   \n",
      "1  https://trendlyne.com/get-document/report/pdf/...                 1768.5   \n",
      "2  https://trendlyne.com/get-document/report/pdf/...                 1768.5   \n",
      "3  https://trendlyne.com/get-document/report/pdf/...                 1768.5   \n",
      "4  https://trendlyne.com/get-document/report/pdf/...                 1792.8   \n",
      "\n",
      "  percentage  expected_return   matched_company_name           Company Name  \\\n",
      "0    (8.19%)       -10.535481  havells india limited  havells india limited   \n",
      "1   (12.41%)        21.345773  havells india limited  havells india limited   \n",
      "2   (12.41%)        -2.742437  havells india limited  havells india limited   \n",
      "3   (12.41%)        11.733107  havells india limited  havells india limited   \n",
      "4   (10.89%)        -0.713967  havells india limited  havells india limited   \n",
      "\n",
      "    Symbol  actual_return          Sector  \n",
      "0  HAVELLS      -0.011863  Consumer Goods  \n",
      "1  HAVELLS       0.036465  Consumer Goods  \n",
      "2  HAVELLS       0.039960  Consumer Goods  \n",
      "3  HAVELLS       0.039960  Consumer Goods  \n",
      "4  HAVELLS       0.011188  Consumer Goods  \n"
     ]
    }
   ],
   "source": [
    "# Ensure the DataFrame with unique sectors based on symbols is saved as 'unique_sectors_df'\n",
    "# Assuming 'Symbol' is the column name in both DataFrames\n",
    "\n",
    "# Perform an inner join on 'Symbol' column\n",
    "merged_df = pd.merge(analyst_ratings, unique_sector_df[['Symbol', 'Sector']], on='Symbol', how='inner')\n",
    "\n",
    "# Display the merged DataFrame to confirm\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd9696b7-4647-476d-820a-52cc5173fe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date           Company Name   Symbol                    author  \\\n",
      "0 2024-07-29  havells india limited  HAVELLS        Geojit BNP Paribas   \n",
      "1 2024-07-21  havells india limited  HAVELLS               Anand Rathi   \n",
      "2 2024-07-19  havells india limited  HAVELLS      Keynote Capitals Ltd   \n",
      "3 2024-07-19  havells india limited  HAVELLS       Prabhudas Lilladhar   \n",
      "4 2024-06-05  havells india limited  HAVELLS  BOB Capital Markets Ltd.   \n",
      "\n",
      "           Sector  expected_return  actual_return  \n",
      "0  Consumer Goods       -10.535481      -0.011863  \n",
      "1  Consumer Goods        21.345773       0.036465  \n",
      "2  Consumer Goods        -2.742437       0.039960  \n",
      "3  Consumer Goods        11.733107       0.039960  \n",
      "4  Consumer Goods        -0.713967       0.011188  \n"
     ]
    }
   ],
   "source": [
    "# Select only the desired columns from merged_df\n",
    "filtered_df = merged_df[['date', 'Company Name', 'Symbol', 'author', 'Sector', 'expected_return', 'actual_return']]\n",
    "\n",
    "# Display the filtered DataFrame to verify\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64203ae1-b91f-446e-8f85-58b1a855a6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Sector                                       Company Name  \\\n",
      "0      Consumer Goods  havells india limited, go fashion (india) limited   \n",
      "1              Energy                         premier explosives limited   \n",
      "2             Finance  religare enterprises limited, ltimindtree limi...   \n",
      "3          Healthcare  poly medicure limited, allcargo gati limited, ...   \n",
      "4       Manufacturing  vardhman special steels limited, orient paper ...   \n",
      "5          Technology  honeywell automation india limited, pennar ind...   \n",
      "6  Telecommunications                               nandan denim limited   \n",
      "\n",
      "   Company Count  \n",
      "0            230  \n",
      "1              6  \n",
      "2            167  \n",
      "3             41  \n",
      "4            163  \n",
      "5            121  \n",
      "6              7  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Group by 'Sector' and aggregate company names\n",
    "sector_group_details = filtered_df.groupby('Sector').agg({\n",
    "    'Company Name': lambda x: ', '.join(x.unique()),  # Combine company names\n",
    "    'Symbol': 'count'  # Count the number of companies in each sector\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the 'Symbol' column to 'Company Count' for clarity\n",
    "sector_group_details.rename(columns={'Symbol': 'Company Count'}, inplace=True)\n",
    "\n",
    "# Display the sector details\n",
    "print(sector_group_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "215465a0-d547-4076-b30e-4e3e59848e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Sector                                       Company Name  \\\n",
      "0      Consumer Goods  havells india limited, go fashion (india) limited   \n",
      "1              Energy                         premier explosives limited   \n",
      "2             Finance  religare enterprises limited, ltimindtree limi...   \n",
      "3          Healthcare  poly medicure limited, allcargo gati limited, ...   \n",
      "4       Manufacturing  vardhman special steels limited, orient paper ...   \n",
      "5          Technology  honeywell automation india limited, pennar ind...   \n",
      "6  Telecommunications                               nandan denim limited   \n",
      "\n",
      "   Company Count  \n",
      "0            230  \n",
      "1              6  \n",
      "2            167  \n",
      "3             41  \n",
      "4            163  \n",
      "5            121  \n",
      "6              7  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Group by 'Sector' and aggregate company names\n",
    "sector_group_details = filtered_df.groupby('Sector').agg({\n",
    "    'Company Name': lambda x: ', '.join(x.unique()),  # Combine company names\n",
    "    'Symbol': 'count'  # Count the number of companies in each sector\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the 'Symbol' column to 'Company Count' for clarity\n",
    "sector_group_details.rename(columns={'Symbol': 'Company Count'}, inplace=True)\n",
    "\n",
    "# Display the sector details\n",
    "print(sector_group_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e93e5ba-1e1c-4b8e-8efd-40bd2d385da2",
   "metadata": {},
   "source": [
    "# Output Dataframe - Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd95b45b-0fe9-41c5-801c-17c7f4f6731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered_df as a CSV file\n",
    "filtered_df.to_csv('data/filtered_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758daa0-e66e-4416-bee3-d217c41ae59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb76b2-b8a8-42d6-822c-295bc5d2ee03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df935bb8-4710-4d52-836b-b0dc06b2a38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0424f712-32f7-4246-80d0-80bb1a50c7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
